{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ©ç”¨Bertå¾®è°ƒQuestion Answeringä»»åŠ¡\n",
    "1. å‡†å¤‡æ•°æ®\n",
    "* å¯¹äºQAä»»åŠ¡ï¼Œæ•°æ®é€šå¸¸åŒ…æ‹¬é—®é¢˜ï¼ˆquestionï¼‰ã€ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰å’Œç­”æ¡ˆï¼ˆanswerï¼‰ã€‚ä¸Šä¸‹æ–‡ä¸­åŒ…å«é—®é¢˜çš„ç­”æ¡ˆï¼Œè€Œç­”æ¡ˆåœ¨ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®éœ€è¦é€šè¿‡å­—ç¬¦åç§»æ¥æ ‡è®°ã€‚ä»¥SQuADï¼ˆStanford Question Answering Datasetï¼‰ä¸ºä¾‹ï¼Œæ•°æ®é›†åŒ…å«äº†å¤šä¸ªé—®é¢˜-ä¸Šä¸‹æ–‡-ç­”æ¡ˆçš„æ ·æœ¬ã€‚\n",
    "2. é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "* æˆ‘ä»¬ä½¿ç”¨Hugging Faceçš„Transformersåº“åŠ è½½BERTæ¨¡å‹åŠå…¶åˆ†è¯å™¨ï¼ˆå¦‚bert-base-uncasedï¼‰ã€‚åˆ†è¯å™¨è´Ÿè´£å°†é—®é¢˜å’Œä¸Šä¸‹æ–‡æ‹¼æ¥å¹¶è½¬ä¸ºæ¨¡å‹è¾“å…¥çš„tokenã€‚\n",
    "3. æ•°æ®é¢„å¤„ç†\n",
    "* åœ¨QAä»»åŠ¡ä¸­ï¼Œéœ€è¦å°†é—®é¢˜å’Œä¸Šä¸‹æ–‡åˆ†è¯ï¼Œå¹¶å¤„ç†ä»¥ä¸‹å‡ æ–¹é¢ï¼š\n",
    "    * Tokenizeé—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼šå°†é—®é¢˜å’Œä¸Šä¸‹æ–‡æ‹¼æ¥æˆæ¨¡å‹è¾“å…¥ï¼Œå¹¶è¿›è¡Œåˆ†è¯ã€‚åˆ†è¯åç¡®ä¿é•¿åº¦ä¸è¶…è¿‡æ¨¡å‹çš„æœ€å¤§è¾“å…¥é™åˆ¶ã€‚\n",
    "    * æ ‡è®°ç­”æ¡ˆä½ç½®ï¼šå°†ç­”æ¡ˆçš„å­—ç¬¦ä½ç½®è½¬æ¢ä¸ºtokençš„ä½ç½®ç´¢å¼•ï¼Œæ ‡è®°å‡ºç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸä½ç½®ã€‚\n",
    "    * æ— ç­”æ¡ˆæƒ…å†µï¼šåœ¨ä¸€äº›æ•°æ®é›†ä¸­ï¼ˆå¦‚SQuAD v2ï¼‰ï¼Œé—®é¢˜å¯èƒ½æ²¡æœ‰ç­”æ¡ˆï¼Œè¿™æ—¶è®¾ç½®ç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸä½ç½®ä¸º0ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ è¯†åˆ«æ— ç­”æ¡ˆçš„æƒ…å†µã€‚\n",
    "4. è®¾ç½®è®­ç»ƒå‚æ•°\n",
    "5. å¾®è°ƒæ¨¡å‹\n",
    "* ä½¿ç”¨Trainer APIæ¥ç®¡ç†å¾®è°ƒè¿‡ç¨‹ã€‚Traineræ¥å—æ¨¡å‹ã€è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„è¶…å‚æ•°æ¥æ‰§è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚è¿™ä¸€APIå°è£…äº†å¸¸è§çš„è®­ç»ƒæ­¥éª¤ï¼Œæ¯”å¦‚å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æ¢¯åº¦æ›´æ–°ç­‰ï¼Œå¤§å¤§ç®€åŒ–äº†å¾®è°ƒæµç¨‹ã€‚\n",
    "6. éªŒè¯ä¸è¯„ä¼°æ¨¡å‹\n",
    "* å¾®è°ƒå®Œæˆåï¼Œå¯ä»¥åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹è¡¨ç°ã€‚é€šè¿‡è®¾å®šéªŒè¯æŒ‡æ ‡ï¼ˆå¦‚F1-scoreæˆ–å‡†ç¡®ç‡ï¼‰ï¼Œå¯ä»¥æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰æ•ˆåœ°æ‰¾åˆ°äº†ç­”æ¡ˆã€‚\n",
    "7. è¿›è¡Œæ¨ç†\n",
    "* å¾®è°ƒåçš„æ¨¡å‹å¯ä»¥ç”¨äºå®é™…çš„QAä»»åŠ¡ï¼Œå³è¾“å…¥æ–°çš„é—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡æ‰¾åˆ°å¹¶è¾“å‡ºç­”æ¡ˆã€‚è¿™é€šå¸¸é€šè¿‡è¾“å…¥é—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œæ¨¡å‹ç”Ÿæˆé¢„æµ‹çš„å¼€å§‹å’Œç»“æŸä½ç½®ï¼Œå°†å¯¹åº”çš„tokenè½¬æ¢ä¸ºç­”æ¡ˆæ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bertæ˜¯æ€ä¹ˆå®ç°Question Answeringä»»åŠ¡çš„ï¼Ÿ\n",
    "BERTå®ç°Question Answeringï¼ˆQAï¼‰ä»»åŠ¡æ—¶ï¼Œé€šè¿‡è¾“å…¥é—®é¢˜ï¼ˆQuestionï¼‰å’Œä¸Šä¸‹æ–‡ï¼ˆContextï¼‰æ¥é¢„æµ‹ç­”æ¡ˆåœ¨ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®ã€‚BERTåœ¨QAä»»åŠ¡ä¸­çš„è¾“å‡ºä¸ºç­”æ¡ˆåœ¨ä¸Šä¸‹æ–‡ä¸­çš„â€œèµ·å§‹ä½ç½®â€å’Œâ€œç»“æŸä½ç½®â€çš„æ¦‚ç‡ï¼Œè¿™äº›æ¦‚ç‡æŒ‡å‘äº†ä¸Šä¸‹æ–‡ä¸­åŒ…å«ç­”æ¡ˆçš„å­å¥æˆ–ç‰‡æ®µ\n",
    "1. è¾“å…¥æ ¼å¼\n",
    "* åœ¨QAä»»åŠ¡ä¸­ï¼Œè¾“å…¥æ•°æ®ç”±ä¸€ä¸ªé—®é¢˜å’Œä¸€ä¸ªä¸Šä¸‹æ–‡ç»„æˆï¼Œå°†äºŒè€…è¿›è¡Œæ‹¼æ¥ï¼Œæ„æˆBERTçš„æ ‡å‡†è¾“å…¥æ ¼å¼ï¼š[CLS] é—®é¢˜ [SEP] ä¸Šä¸‹æ–‡ [SEP]\n",
    "    * [CLS]æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„èµ·å§‹æ ‡å¿—ï¼ŒBERTåœ¨é¢„è®­ç»ƒæ—¶ä¼šå¯¹è¿™ä¸ªæ ‡å¿—çš„è¾“å‡ºè¿›è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œå› æ­¤å¯ä»¥åœ¨QAä»»åŠ¡ä¸­ä½¿ç”¨å®ƒæ¥æŒ‡å¼•æ¨¡å‹ã€‚\n",
    "    * [SEP]æ˜¯åˆ†éš”ç¬¦ï¼Œç”¨æ¥åŒºåˆ†é—®é¢˜å’Œä¸Šä¸‹æ–‡ã€‚\n",
    "2. Bertçš„è¾“å‡º\n",
    "* è¾“å…¥ç»è¿‡ç¼–ç åä¼šç”Ÿæˆå¯¹åº”çš„è¾“å‡ºå‘é‡ã€‚å‡è®¾è¾“å…¥æœ‰nä¸ªtokenï¼ŒBERTä¼šç”Ÿæˆä¸€ä¸ªnä¸ªtokenå¯¹åº”çš„è¾“å‡ºå‘é‡ã€‚å¯¹äºQAä»»åŠ¡ï¼Œæ¯ä¸ªtokençš„ä½ç½®å‘é‡ç»è¿‡è¿›ä¸€æ­¥çš„å¤„ç†ï¼Œç”¨äºé¢„æµ‹å®ƒæ˜¯å¦ä¸ºç­”æ¡ˆçš„èµ·å§‹æˆ–ç»“æŸä½ç½®ã€‚\n",
    "3. ç­”æ¡ˆèµ·å§‹å’Œç»“æŸä½ç½®é¢„æµ‹\n",
    "* BERTåœ¨QAä»»åŠ¡ä¸­å¢åŠ äº†ä¸¤ä¸ªåˆ†ç±»å¤´ï¼ˆClassification Headï¼‰ï¼Œç”¨äºé¢„æµ‹ç­”æ¡ˆçš„â€œèµ·å§‹ä½ç½®â€å’Œâ€œç»“æŸä½ç½®â€ã€‚è¿™äº›å¤´éƒ¨æ˜¯ä¸¤ä¸ªçº¿æ€§å±‚ï¼Œåˆ†åˆ«è®¡ç®—æ¯ä¸ªtokenæ˜¯ç­”æ¡ˆèµ·å§‹æˆ–ç»“æŸä½ç½®çš„æ¦‚ç‡ã€‚\n",
    "    * èµ·å§‹ä½ç½®é¢„æµ‹ï¼šBERTé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚è®¡ç®—æ¯ä¸ªtokenæ˜¯ç­”æ¡ˆèµ·å§‹ä½ç½®çš„æ¦‚ç‡ã€‚è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒè¡¨ç¤ºæ¯ä¸ªtokenä½œä¸ºç­”æ¡ˆèµ·å§‹çš„å¯èƒ½æ€§ã€‚\n",
    "    * ç»“æŸä½ç½®é¢„æµ‹ï¼šåŒæ ·ï¼ŒBERTä½¿ç”¨å¦ä¸€ä¸ªçº¿æ€§å±‚è®¡ç®—æ¯ä¸ªtokenæ˜¯ç­”æ¡ˆç»“æŸä½ç½®çš„æ¦‚ç‡ã€‚\n",
    "* æ¨¡å‹åœ¨è®­ç»ƒæ—¶ä¼šå­¦ä¹ åˆ°æ¯ä¸ªtokençš„è¾“å‡ºå‘é‡ä¸ç­”æ¡ˆä½ç½®ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå¹¶é€šè¿‡è®¡ç®—äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œä½¿é¢„æµ‹ç»“æœä¸å®é™…ç­”æ¡ˆä½ç½®æ¥è¿‘ã€‚\n",
    "4. æŸå¤±å‡½æ•°\n",
    "* QAä»»åŠ¡ä¸­çš„æŸå¤±å‡½æ•°ç”±èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®çš„é¢„æµ‹æŸå¤±å…±åŒç»„æˆï¼Œå…·ä½“è®¡ç®—æ–¹å¼ä¸ºï¼š\n",
    "    * Loss=CrossEntropyLoss(start_logits,true_start)+CrossEntropyLoss(end_logits,true_end)\n",
    "        * start_logitså’Œend_logitsåˆ†åˆ«æ˜¯æ¨¡å‹é¢„æµ‹çš„æ¯ä¸ªtokenä½œä¸ºç­”æ¡ˆèµ·å§‹æˆ–ç»“æŸä½ç½®çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "        * true_startå’Œtrue_endåˆ†åˆ«æ˜¯æ ‡ç­¾æ•°æ®ä¸­çš„çœŸå®ç­”æ¡ˆèµ·å§‹å’Œç»“æŸä½ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. å¯¼åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. å¯¼å…¥æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130319/130319 [00:00<00:00, 918949.34 examples/s]\n",
      "Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11873/11873 [00:00<00:00, 1025577.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®é›†ï¼Œè¿™é‡Œä»¥SQuAD v2ä¸ºä¾‹\n",
    "dataset = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130319/130319 [01:57<00:00, 1106.93 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11873/11873 [00:09<00:00, 1295.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        if len(answer[\"answer_start\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answer[\"text\"][0])\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "            # å°†å­—ç¬¦ä½ç½®æ˜ å°„åˆ°tokenä½ç½®\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(sequence_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offset[token_start_index][0] <= start_char and offset[token_end_index][1] >= end_char):\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                while token_start_index < len(offset) and offset[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                start_positions.append(token_start_index - 1)\n",
    "\n",
    "                while offset[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                end_positions.append(token_end_index + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. è®¾ç½®è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 500/24435 [15:57<10:27:46,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6578, 'grad_norm': 12.769356727600098, 'learning_rate': 1.9590750971966443e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1000/24435 [28:47<9:56:02,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7902, 'grad_norm': 22.286327362060547, 'learning_rate': 1.9181501943932885e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 1483/24435 [41:00<9:59:37,  1.57s/it] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2452\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2452\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2456\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/accelerate/optimizer.py:171\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    210\u001b[0m         group,\n\u001b[1;32m    211\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         state_steps,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 782\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:427\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    425\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# æ²¡GPUï¼Œè·‘çš„å¤ªæ…¢äº†ï¼Œå…ˆä¸è·‘äº†\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. éªŒè¯å’Œæµ‹è¯•æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, context):\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "    return answer\n",
    "\n",
    "# ç¤ºä¾‹\n",
    "question = \"What is Transformers library?\"\n",
    "context = \"The Transformers library by Hugging Face is a collection of pretrained models for NLP.\"\n",
    "print(answer_question(question, context))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
