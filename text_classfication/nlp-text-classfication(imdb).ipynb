{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bertç”¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„åº”ç”¨æ­¥éª¤\n",
    "1. é¢„è®­ç»ƒé˜¶æ®µ<br>\n",
    "Berté€šè¿‡å¤§è§„æ¨¡çš„æ— æ ‡ç­¾æ–‡æœ¬æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ äº†ä¸°å¯Œçš„è¯­è¨€è¡¨ç¤º\n",
    "* æ©ç è¯­è¨€æ¨¡å‹ï¼ˆMasked Language Modelï¼ŒMLMï¼‰ï¼šéšæœºé®æ©è¾“å…¥æ–‡æœ¬ä¸­çš„ä¸€äº›å•è¯ï¼Œæ¨¡å‹çš„ä»»åŠ¡å°±æ˜¯é¢„æµ‹è¢«é®æ©çš„å•è¯ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç†è§£ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼›\n",
    "* ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ï¼ˆNext Sentence Predictionï¼ŒNSPï¼‰ï¼šè¾“å…¥ä¸¤ä¸ªå¥å­ï¼Œæ¨¡å‹éœ€è¦åˆ¤æ–­ç¬¬äºŒä¸ªå¥å­æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªå¥å­çš„åç»­ã€‚\n",
    "\n",
    "2. å¾®è°ƒé˜¶æ®µ<br>\n",
    "åœ¨é¢„è®­ç»ƒä¹‹åï¼Œå¯ä»¥é€šè¿‡å°†Bertå¾®è°ƒæ¥é€‚åº”ç‰¹å®šçš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡\n",
    "* æ•°æ®å‡†å¤‡ï¼šå‡†å¤‡å¥½å¸¦æ ‡ç­¾çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬æ–‡æœ¬åŠå…¶å¯¹åº”çš„åˆ†ç±»æ ‡ç­¾\n",
    "* æ¨¡å‹æ„å»ºï¼šä½¿ç”¨`BertForSequenceClassification`ç­‰ç±»åŠ è½½é¢„è®­ç»ƒçš„Bertæ¨¡å‹ï¼Œå¹¶æé‚£å®¶ä¸€ä¸ªåˆ†ç±»å±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰æ¥è¾“å‡ºåˆ†ç±»ç»“æœ\n",
    "* è¾“å…¥æ ¼å¼åŒ–ï¼šå°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºBertå¯ä»¥æ¥å—çš„æ ¼å¼\n",
    "    * Tokenizationï¼šä½¿ç”¨Bertçš„åˆ†è¯å™¨å°†æ–‡æœ¬è½¬æ¢ä¸ºtoken IDï¼Œå¹¶è¿›è¡Œå¡«å……\n",
    "    * Attention Maskï¼šç”Ÿæˆä¸€ä¸ªMaskï¼ŒæŒ‡ç¤ºæ¨¡å‹åº”è¯¥å…³æ³¨å“ªäº›tokenï¼ˆ1è¡¨ç¤ºæœ‰æ•ˆtokenï¼Œ0è¡¨ç¤ºå¡«å……tokenï¼‰\n",
    "\n",
    "3. è®­ç»ƒ<br>\n",
    "åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡ä½¿ç”¨å¸¦æ ‡ç­¾çš„è®­ç»ƒæ•°æ®å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚æ¨¡å‹ä¼šæ ¹æ®è¾“å…¥æ–‡æœ¬å’Œç›¸åº”çš„æ ‡ç­¾è°ƒæ•´å…¶æƒé‡ï¼Œä»¥æœ€å¤§åŒ–æ­£ç¡®åˆ†ç±»çš„æ¦‚ç‡ã€‚ä½¿ç”¨æŸå¤±å‡½æ•°ï¼ˆå¦‚äº¤å‰ç†µæŸå¤±ï¼‰æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚\n",
    "\n",
    "4. è¯„ä¼°ä¸é¢„æµ‹<br>\n",
    "åœ¨è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨éªŒè¯é›†æˆ–æµ‹è¯•é›†å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä»¥ç¡®å®šå…¶åˆ†ç±»æ€§èƒ½ã€‚æ¨¡å‹å¯ä»¥è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®æœ€å¤§æ¦‚ç‡è¿›è¡Œç±»åˆ«åˆ¤æ–­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. å¯¼åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# BertForSequenceClassificationï¼šHugging Face transformersåº“ä¸­çš„ä¸€ä¸ªç±»ï¼Œä¸“é—¨ç”¨äºå¤„ç†åºåˆ—åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚æƒ…æ„Ÿåˆ†æã€ä¸»é¢˜åˆ†ç±»ç­‰\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. åŠ è½½é¢„è®­ç»ƒçš„BERTæ¨¡å‹å’Œåˆ†è¯å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"  # å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„BERTç‰ˆæœ¬\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name) # åˆ†è¯å™¨\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # é€‚ç”¨äºäºŒåˆ†ç±»\n",
    "# :param model_name: æŒ‡å®šè¦åŠ è½½çš„é¢„è®­ç»ƒBERTæ¨¡å‹çš„åç§°æˆ–è€…è·¯å¾„\n",
    "# :param num_labels: æŒ‡å®šæ¨¡å‹çš„è¾“å‡ºæ ‡ç­¾æ•°é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. åŠ è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®é›†ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯ Hugging Face è‡ªå¸¦çš„ dataset åº“\n",
    "dataset = load_dataset(\"imdb\")  # ç¤ºä¾‹æ˜¯IMDBå½±è¯„åˆ†ç±»ä»»åŠ¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
      "2  If only to avoid making this type of film in t...      0\n",
      "3  This film was probably inspired by Godard's Ma...      0\n",
      "4  Oh, brother...after hearing about this ridicul...      0\n"
     ]
    }
   ],
   "source": [
    "df_train=dataset['train'].to_pandas()\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
      "2  If only to avoid making this type of film in t...      0\n",
      "3  This film was probably inspired by Godard's Ma...      0\n",
      "4  Oh, brother...after hearing about this ridicul...      0\n"
     ]
    }
   ],
   "source": [
    "df_test=dataset['train'].to_pandas()\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. å®šä¹‰æ•°æ®é¢„å¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é¢„å¤„ç†å‡½æ•°ï¼Œå°†æ–‡æœ¬è½¬åŒ–ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. æ•°æ®é›†é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ•°æ®é›†è¿›è¡Œåˆ†è¯å’Œç¼–ç \n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. æ¨¡å‹å®šä¹‰ä¸ç¼–è¯‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»æ•°æ®é›†ä¸­æŠ½å–ä¸€éƒ¨åˆ†æ ·æœ¬ç”¨äºdebugæ¨¡å¼\n",
    "small_train_dataset = encoded_dataset['train'].select(range(100))  # æŠ½å–100ä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†\n",
    "small_eval_dataset = encoded_dataset['test'].select(range(100))    # æŠ½å–100ä¸ªæ ·æœ¬ä½œä¸ºéªŒè¯é›†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # è¾“å‡ºç»“æœä¿å­˜çš„è·¯å¾„\n",
    "    evaluation_strategy=\"epoch\",     # åœ¨æ¯ä¸ªepochåè¿›è¡ŒéªŒè¯\n",
    "    per_device_train_batch_size=16,  # è®­ç»ƒæ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=64,   # éªŒè¯æ‰¹é‡å¤§å°\n",
    "    num_train_epochs=3,              # è®­ç»ƒçš„epochæ•°\n",
    "    weight_decay=0.01,               # æƒé‡è¡°å‡\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨Trainer APIæ¥è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯\n",
    "trainer = Trainer(\n",
    "    model=model,                         # è¦è®­ç»ƒçš„æ¨¡å‹\n",
    "    args=training_args,                  # è®­ç»ƒå‚æ•°\n",
    "    train_dataset=small_train_dataset,  # è®­ç»ƒé›†\n",
    "    eval_dataset=small_eval_dataset,    # éªŒè¯é›†\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 7/21 [00:22<00:32,  2.34s/it]\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 7/21 [00:27<00:32,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09301885962486267, 'eval_runtime': 4.9323, 'eval_samples_per_second': 20.275, 'eval_steps_per_second': 0.405, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [00:41<00:13,  1.86s/it]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [00:46<00:13,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.028304338455200195, 'eval_runtime': 4.9948, 'eval_samples_per_second': 20.021, 'eval_steps_per_second': 0.4, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:09<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01811107248067856, 'eval_runtime': 6.7211, 'eval_samples_per_second': 14.879, 'eval_steps_per_second': 0.298, 'epoch': 3.0}\n",
      "{'train_runtime': 69.3774, 'train_samples_per_second': 4.324, 'train_steps_per_second': 0.303, 'train_loss': 0.13575719651721774, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=0.13575719651721774, metrics={'train_runtime': 69.3774, 'train_samples_per_second': 4.324, 'train_steps_per_second': 0.303, 'total_flos': 78933316608000.0, 'train_loss': 0.13575719651721774, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert_text_classification/tokenizer_config.json',\n",
       " './bert_text_classification/special_tokens_map.json',\n",
       " './bert_text_classification/vocab.txt',\n",
       " './bert_text_classification/added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "model.save_pretrained('./bert_text_classification')\n",
    "tokenizer.save_pretrained('./bert_text_classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
